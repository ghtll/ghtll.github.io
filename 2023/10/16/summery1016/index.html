<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="模型压缩总结, ヾ(≧∪≦*)ノ〃">
    <meta name="description" content="总结近期的文章">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>模型压缩总结 | ヾ(≧∪≦*)ノ〃</title>
    <link rel="icon" type="image/png" href="/ght.png">
    
    <style>
        body{
            background-image: url(https://cdn.jsdelivr.net/gh/Tokisaki-Galaxy/res/site/medias/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/css/post.css">



    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ヾ(≧∪≦*)ノ〃</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ヾ(≧∪≦*)ノ〃</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/ghtll/ghtll.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/ghtll/ghtll.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">模型压缩总结</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="container content">

    
    <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/">
                                <span class="chip bg-color">模型压缩</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" class="post-category">
                                文献阅读
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-10-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2023-11-06
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    20 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-Losparse"><a href="#1-Losparse" class="headerlink" title="1 Losparse"></a>1 Losparse</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>LoSparse: Structured Compression of Large LanguageModels based on Low-Rank and Sparse Approximation ∗</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>ICML</td>
</tr>
<tr>
<td>发表时间</td>
<td>2023.7</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/yxli2123/LoSparse">yxli2123&#x2F;LoSparse (github.com)</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>低秩近似、结构剪枝</td>
</tr>
</tbody></table>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>将权重近似为(将这种分解应用于模型的每个权重矩阵)：<br>$$<br>W&#x3D;UV+S<br>$$<br><img src="/../images/summery1016_imgs/1.png"></p>
<p>重要性评分公式方法：</p>
<p><img src="/../images/summery1016_imgs/2.png" alt="image-20231016142137668"></p>
<p><img src="/../images/summery1016_imgs/43.png"></p>
<h2 id="i"><a href="#i" class="headerlink" title="i"></a>i</h2><p>剪枝采用迭代剪枝，在迭代过程中S的重要性评估不稳定，原文采用平滑+大batchsize。由于样本造成的不稳定，这里可以想一个办法。要不让样本更稳定，要不更换一个重要性评估方法。</p>
<p>初始化$U^0$和$V^0$会丢失很多知识，在文中，矩阵分解占比仅有1-5％，其余都是S的占比。如果在不增加UV的占比情况下提高他的知识，是否可以去除更多的S？考虑加权分解。先加权分解UV，在迭代剪枝。最后微调？</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>评估任务：</strong>natural language understanding (NLU)、question answering (QA)、natural language generation (NLG)</p>
<p><strong>压缩模型：</strong>DeBERTaV3-base、, BERT-base、BART-large</p>
<p><strong>Baselines:</strong> Full fine-tuning 、Movement pruning、Iterative pruning (ITP)</p>
<h3 id="Natural-Language-Understanding"><a href="#Natural-Language-Understanding" class="headerlink" title="Natural Language Understanding"></a>Natural Language Understanding</h3><p>在通用语言理解评估（GLUE）基准上修剪DeBERTaV3-base模型：</p>
<p><img src="/../images/summery1016_imgs/3.png"></p>
<p>修剪bert：</p>
<p><img src="/../images/summery1016_imgs/4.png"></p>
<h3 id="Question-Answering"><a href="#Question-Answering" class="headerlink" title="Question Answering"></a>Question Answering</h3><p>在SQuADv1.1上压缩了DeBERTaV3-base和BERT-base:</p>
<p><img src="/../images/summery1016_imgs/5.png"></p>
<h3 id="Natural-Language-Generation"><a href="#Natural-Language-Generation" class="headerlink" title="Natural Language Generation"></a>Natural Language Generation</h3><p>在XSum和CNN&#x2F;DailyMail数据集上压缩BART-large：</p>
<p><img src="/../images/summery1016_imgs/6.png"></p>
<h1 id="2-LoRAPrune"><a href="#2-LoRAPrune" class="headerlink" title="2 LoRAPrune"></a>2 LoRAPrune</h1><h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>PRUNING MEETS LOW-RANK PARAMETER-EFFICIENT FINE-TUNING</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023.3</td>
</tr>
<tr>
<td>代码</td>
<td>无</td>
</tr>
<tr>
<td>压缩技术</td>
<td>剪枝 SOTA</td>
</tr>
</tbody></table>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/10.png"></p>
<p>插入lora，用lora的梯度代替权重的梯度。</p>
<p>使用一阶泰勒展开式来近似的重要性过于复杂，因此改为使用BA的梯度：</p>
<p><img src="/../images/summery1016_imgs/7.png"></p>
<p><img src="/../images/summery1016_imgs/8.png"></p>
<p>BA梯度仍然复杂，因此继续近似：</p>
<p><img src="/../images/summery1016_imgs/9.png"></p>
<p><img src="/../images/summery1016_imgs/44.png"></p>
<h2 id="i-1"><a href="#i-1" class="headerlink" title="i"></a>i</h2><p>用lora代替w进行计算。前百分之10与后百分之30只涉及参数更新。修剪过程采用“修剪-微调-修剪方法”。</p>
<h2 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h2><p><strong>任务</strong>：VTB-1k(19 个图像分类数据集)、FGVC(CUB-200-2011、NABirds、Oxford Flowers、Stanford Cars 和 Stanford Dogs)、GLUE(CoLA、SST-2、MRPC、STS-B、QQP、MNLI、QNLI、RTE 等任务)</p>
<p>对于CV任务采用ViT-B&#x2F;16模型，对于NLP任务采用 BERT-base模型（RTX3090）</p>
<p>对比：幅值修剪（MaP）、带LoRA的幅值修剪（MaP-LoRA）、运动修剪（MvP）、随机修剪（RaP）、参数高效稀疏性（PST）</p>
<p>结果（<strong>微调和剪枝过程结合在一起是高效</strong>）：</p>
<p><img src="/../images/summery1016_imgs/11.png"></p>
<p><img src="/../images/summery1016_imgs/12.png"></p>
<h1 id="3-PruneOFA"><a href="#3-PruneOFA" class="headerlink" title="3 PruneOFA"></a>3 PruneOFA</h1><h2 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Prune Once for All: Sparse Pre-Trained Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2021.11</td>
</tr>
<tr>
<td>代码</td>
<td></td>
</tr>
<tr>
<td>压缩技术</td>
<td>非结构化剪枝、蒸馏</td>
</tr>
</tbody></table>
<h2 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h2><p>采用渐进幅度修剪：</p>
<p><img src="/../images/summery1016_imgs/13.png"></p>
<p>流程：</p>
<p><img src="/../images/summery1016_imgs/14.png"></p>
<p>提出模式锁的方法，它可以防止在训练模型时改变模型中发现的零</p>
<h2 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h2><p>模型：BERT-Base, BERT-Large and DistilBERT</p>
<p><img src="/../images/summery1016_imgs/15.png"></p>
<p><img src="/../images/summery1016_imgs/16.png"></p>
<p><img src="/../images/summery1016_imgs/17.png"></p>
<h1 id="4-oBert"><a href="#4-oBert" class="headerlink" title="4 oBert"></a>4 oBert</h1><h2 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>EMNLP</td>
</tr>
<tr>
<td>发表时间</td>
<td>2022.10</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT">sparseml&#x2F;research&#x2F;optimal_BERT_surgeon_oBERT at main · neuralmagic&#x2F;sparseml (github.com)</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>非结构化剪枝</td>
</tr>
</tbody></table>
<h2 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h2><p>采用二阶Hassian矩阵近似重要性进行剪枝：</p>
<p><img src="/../images/summery1016_imgs/18.png"></p>
<p>采用经验fisher矩阵近似hassian矩阵：</p>
<p><img src="/../images/summery1016_imgs/19.png"></p>
<h2 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h2><p>比较方法：Movement Pruning (MvP)、Lottery Ticket (LT-BERT)</p>
<p><img src="/../images/summery1016_imgs/20.png"></p>
<p><img src="/../images/summery1016_imgs/21.png"></p>
<h1 id="5-FLOP"><a href="#5-FLOP" class="headerlink" title="5 FLOP"></a>5 FLOP</h1><h2 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Structured Pruning of Large Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>EMNLP</td>
</tr>
<tr>
<td>发表时间</td>
<td>2021.5</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT">sparseml&#x2F;research&#x2F;optimal_BERT_surgeon_oBERT at main · neuralmagic&#x2F;sparseml (github.com)</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>低秩近似、结构化剪枝</td>
</tr>
</tbody></table>
<h3 id="方法-4"><a href="#方法-4" class="headerlink" title="方法"></a>方法</h3><p>端到端的训练方法，优化目标：</p>
<p><img src="/../images/summery1016_imgs/22.png"></p>
<p>重新参数化技巧：</p>
<p><img src="/../images/summery1016_imgs/23.png"></p>
<p>利用低秩因子分解的权重矩阵参数化方法：</p>
<p><img src="/../images/summery1016_imgs/24.png"></p>
<p>增强拉格朗日方法：</p>
<p><img src="/../images/summery1016_imgs/25.png"></p>
<p>优化的最终目标：</p>
<p><img src="/../images/summery1016_imgs/26.png"></p>
<h2 id="实验-4"><a href="#实验-4" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/27.png"></p>
<h1 id="6-FWSVD"><a href="#6-FWSVD" class="headerlink" title="6 FWSVD"></a>6 FWSVD</h1><h2 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>LANGUAGE MODEL COMPRESSION WITH WEIGHTED LOW-RANK FACTORIZATION</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>ICLR</td>
</tr>
<tr>
<td>发表时间</td>
<td>2022.6</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/RahulSChand/Weighted-low-rank-factorization-Pytorch">https://github.com/RahulSChand/Weighted-low-rank-factorization-Pytorch</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>加权分解</td>
</tr>
</tbody></table>
<h3 id="方法-5"><a href="#方法-5" class="headerlink" title="方法"></a>方法</h3><p>矩阵分解：</p>
<p><img src="/../images/summery1016_imgs/28.png"></p>
<p>Fisher信息：</p>
<p><img src="/../images/summery1016_imgs/29.png"></p>
<p>费雪加权低秩近似：</p>
<p><img src="/../images/summery1016_imgs/30.png"></p>
<h2 id="i-2"><a href="#i-2" class="headerlink" title="i"></a>i</h2><p>微调lora（保留增量梯度）-&gt;计算重要性-&gt;加权分解SVD-&gt;W&#x3D;BA+S剪枝（剪枝S，微调BA）</p>
<p>W每一行相同的权重，否则没有闭环解？如何改进。</p>
<p><strong>单词嵌入层(非负矩阵分解，考虑人脸识别和数字分解)</strong></p>
<h2 id="实验-5"><a href="#实验-5" class="headerlink" title="实验"></a>实验</h2><p>压缩路径：</p>
<p><img src="/../images/summery1016_imgs/31.png"></p>
<p><img src="/../images/summery1016_imgs/32.png"></p>
<h1 id="7-LLM-Pruner"><a href="#7-LLM-Pruner" class="headerlink" title="7 LLM-Pruner"></a>7 LLM-Pruner</h1><h2 id="简介-6"><a href="#简介-6" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>LLM-Pruner: On the Structural Pruning of Large Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>NeurlPS</td>
</tr>
<tr>
<td>发表时间</td>
<td>2023.9</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/horseee/LLM-Pruner">https://github.com/horseee/LLM-Pruner</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>结构剪枝+LoRA微调</td>
</tr>
</tbody></table>
<h2 id="方法-6"><a href="#方法-6" class="headerlink" title="方法"></a>方法</h2><p>发现依赖结构-&gt;评估重要性(采用二阶导数)-&gt;微调恢复</p>
<h2 id="实验-6"><a href="#实验-6" class="headerlink" title="实验"></a>实验</h2><p>无baselines</p>
<p><img src="/../images/summery1016_imgs/33.png"></p>
<h1 id="8-SHEARED-LLAMA"><a href="#8-SHEARED-LLAMA" class="headerlink" title="8 SHEARED LLAMA"></a>8 SHEARED LLAMA</h1><h2 id="简介-7"><a href="#简介-7" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>SHEARED LLAMA: ACCELERATING LANGUAGE MODEL PRE-TRAINING VIA STRUCTURED PRUNING</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023.10</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/horseee/LLM-Pruner">https://github.com/horseee/LLM-Pruner</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>结构剪枝+动态批量加载</td>
</tr>
</tbody></table>
<h2 id="方法-7"><a href="#方法-7" class="headerlink" title="方法"></a>方法</h2><p>微调对于结构剪枝至关重要</p>
<p>端到端剪枝</p>
<p><img src="/../images/summery1016_imgs/34.png"></p>
<p>根据训练数据比例动态加载训练数据</p>
<h2 id="实验-7"><a href="#实验-7" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/35.png"></p>
<h1 id="9-ZipLM"><a href="#9-ZipLM" class="headerlink" title="9 ZipLM"></a>9 ZipLM</h1><h2 id="简介-8"><a href="#简介-8" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>ZipLM: Hardware-Aware Structured Pruning of Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023.2</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/horseee/LLM-Pruner">https://github.com/horseee/LLM-Pruner</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>结构剪枝+知识蒸馏</td>
</tr>
</tbody></table>
<h2 id="方法-8"><a href="#方法-8" class="headerlink" title="方法"></a>方法</h2><p>一次剪枝一个结构来解决相关性问题。</p>
<p>权重更新，二阶导数近似：</p>
<p><img src="/../images/summery1016_imgs/36.png"></p>
<p>蒸馏：</p>
<p><img src="/../images/summery1016_imgs/37.png"></p>
<h2 id="实验-8"><a href="#实验-8" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/38.png"></p>
<h1 id="10-Matrix-Decomposition"><a href="#10-Matrix-Decomposition" class="headerlink" title="10 Matrix Decomposition"></a>10 Matrix Decomposition</h1><h2 id="简介-9"><a href="#简介-9" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Compressing Pre-trained Language Models by Matrix Decomposition</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>AACl</td>
</tr>
<tr>
<td>发表时间</td>
<td>2021</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/kene111/matrix-decomposition">https://github.com/kene111/matrix-decomposition</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>低秩分解+蒸馏</td>
</tr>
</tbody></table>
<h2 id="方法-9"><a href="#方法-9" class="headerlink" title="方法"></a>方法</h2><ol>
<li><p>通过SVD分解</p>
</li>
<li><p>知识蒸馏，训练损失由三部分构成：<br>$$<br>L&#x3D;\alpha L_{CE}+(1-\alpha)L_{KD}+L_{FD}<br>$$<br><img src="/../images/summery1016_imgs/39.png"></p>
</li>
</ol>
<p><img src="/../images/summery1016_imgs/40.png"></p>
<p><img src="/../images/summery1016_imgs/41.png"></p>
<p><strong>基础模型(微调模型)用于分解和作为教师模型</strong></p>
<h2 id="实验-9"><a href="#实验-9" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/42.png"></p>
<h1 id="11-Movement-Pruning"><a href="#11-Movement-Pruning" class="headerlink" title="11 Movement Pruning"></a>11 Movement Pruning</h1><h2 id="简介-10"><a href="#简介-10" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Movement Pruning:Adaptive Sparsity by Fine-Tuning</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>NeurIPS</td>
</tr>
<tr>
<td>发表时间</td>
<td>2020</td>
</tr>
<tr>
<td>代码</td>
<td></td>
</tr>
<tr>
<td>压缩技术</td>
<td>移动剪枝</td>
</tr>
</tbody></table>
<h2 id="方法-10"><a href="#方法-10" class="headerlink" title="方法"></a>方法</h2><p>考虑到权重值在迁移学习中不是从头开始的，传统的基于幅度的剪枝可能无法充分适应新任务的需求，因为他们的修剪决策是基于原始模型的权重值。公式推导：</p>
<p><img src="/../images/summery1016_imgs/45.png"></p>
<p><img src="/../images/summery1016_imgs/46.png"></p>
<p><img src="/../images/summery1016_imgs/112.png"></p>
<p><img src="/../images/summery1016_imgs/113.png"></p>
<p>从公式可以看出，当W远离0点是，重要性S变大。于是修剪那些逐渐靠近0的权重而幅度修剪的方法修剪离0近的值。</p>
<p><img src="/../images/summery1016_imgs/114.png"></p>
<h2 id="实验-10"><a href="#实验-10" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/115.png"></p>
<h1 id="12-ITP"><a href="#12-ITP" class="headerlink" title="12 ITP"></a>12 ITP</h1><h2 id="简介-11"><a href="#简介-11" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Importance Estimation for Neural Network Pruning</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>CVPR</td>
</tr>
<tr>
<td>发表时间</td>
<td>2019</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/NVlabs/Taylor_pruning">https://github.com/NVlabs/Taylor_pruning</a><em>.</em></td>
</tr>
<tr>
<td>压缩技术</td>
<td>迭代剪枝、一阶二阶近似</td>
</tr>
</tbody></table>
<h2 id="方法-11"><a href="#方法-11" class="headerlink" title="方法"></a>方法</h2><p>计算精确的重要性对于大型网络来说是及其昂贵的，然后采用一阶或二阶近似的方法评估重要性。</p>
<p><img src="/../images/summery1016_imgs/121.png" alt="image-20231026144556225"></p>
<p><img src="/../images/summery1016_imgs/122.png"></p>
<p><img src="/../images/summery1016_imgs/123.png"></p>
<p>以一个训练过的网络作为输入，并在一个具有较小学习率的迭代微调过程中对其进行剪枝。在每个时期内，都要重复以下步骤：</p>
<ol>
<li>对于每个小批处理，我们计算参数梯度，并通过梯度下降来更新网络权值。我们还计算了每个神经元（或滤波器）的重要性</li>
<li>在预定义的小批之后，我们将每个神经元（或过滤器）的重要性分数取为小批的平均值，并去除N个重要性分数最小的神经元</li>
</ol>
<h2 id="实验-11"><a href="#实验-11" class="headerlink" title="实验"></a>实验</h2><p>在LSTM上做的实验。</p>
<h1 id="13-HMD"><a href="#13-HMD" class="headerlink" title="13  HMD"></a>13  HMD</h1><h2 id="简介-12"><a href="#简介-12" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Rank and run-time aware compression of NLP Applications</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>EMNLP</td>
</tr>
<tr>
<td>发表时间</td>
<td>2020</td>
</tr>
<tr>
<td>代码</td>
<td></td>
</tr>
<tr>
<td>压缩技术</td>
<td>混合低秩压缩</td>
</tr>
</tbody></table>
<h2 id="方法-12"><a href="#方法-12" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/131.png"></p>
<h2 id="实验-12"><a href="#实验-12" class="headerlink" title="实验"></a>实验</h2><h1 id="14-SPDF"><a href="#14-SPDF" class="headerlink" title="14 SPDF"></a>14 SPDF</h1><h2 id="简介-13"><a href="#简介-13" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>EMNLP</td>
</tr>
<tr>
<td>发表时间</td>
<td>2023</td>
</tr>
<tr>
<td>代码</td>
<td></td>
</tr>
<tr>
<td>压缩技术</td>
<td>剪枝之后恢复剪枝</td>
</tr>
</tbody></table>
<h2 id="方法-13"><a href="#方法-13" class="headerlink" title="方法"></a>方法</h2><p>首先，我们预先训练一个稀疏GPT模型，以减少计算训练的流量。然后，在微调阶段，我们强化GPT模型，允许零权值学习并增加建模能力，以更准确地学习下游任务。采用随机修剪，均匀稀疏的方法</p>
<p>三个假设：</p>
<ol>
<li>在llm的训练前阶段，可以使用高程度的权重稀疏度，同时通过密集的微调来保持下游的精度。</li>
<li>稀疏预训练模型的性能与下游任务中数据集的大小和难度相关。</li>
<li>当我们增加语言模型的规模时，更大的模型在训练前变得更容易接受更高水平的稀疏性。</li>
</ol>
<p><img src="/../images/summery1016_imgs/141.png"></p>
<h2 id="实验-13"><a href="#实验-13" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/142.png"></p>
<h1 id="15-A-Fast-Post-Training-Pruning-Framework-forTransformers"><a href="#15-A-Fast-Post-Training-Pruning-Framework-forTransformers" class="headerlink" title="15 A Fast Post-Training Pruning Framework forTransformers"></a>15 A Fast Post-Training Pruning Framework forTransformers</h1><h2 id="简介-14"><a href="#简介-14" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>A Fast Post-Training Pruning Framework for Transformers</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>NeurIPS</td>
</tr>
<tr>
<td>发表时间</td>
<td>2022</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/WoosukKwon/retraining-free-pruning">https://github.com/WoosukKwon/retraining-free-pruning</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>训练后采用20K数据三分钟剪枝</td>
</tr>
</tbody></table>
<h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>剪枝是降低变压器模型巨大推理成本的一种有效方法。然而，之前关于修剪变压器的工作需要重新训练模型</li>
<li>虽然结构化剪枝方法可以实现高压缩率和加速，但它们通常很难在实践中使用。其中一个原因是在修剪期间或修剪后额外训练的计算成本很高，另一个原因是剪枝管道的高度复杂性，其中每个剪枝阶段通常需要重写训练代码，并引入额外的超参数来进行调优。</li>
<li></li>
</ol>
<h2 id="方法-14"><a href="#方法-14" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/151.png"></p>
<p>定义问题：</p>
<p><img src="/../images/summery1016_imgs/152.png"></p>
<p>二阶近似：</p>
<p><img src="/../images/summery1016_imgs/153.png"></p>
<p>海森近似：</p>
<p><img src="/../images/summery1016_imgs/154.png"></p>
<p><strong>掩码搜索：</strong></p>
<p><img src="/../images/summery1016_imgs/155.png"></p>
<p><img src="/../images/summery1016_imgs/156.png"></p>
<p><strong>掩码重排</strong>：</p>
<p>虽然它简化了问题，但仅使用对角线假设可能无法找到最佳的解决方案，因为它没有考虑到不同掩模变量之间的相互作用。例如，如果在一个图层中有两个注意头发挥着相似的作用，那么只修剪其中一个可能不会影响模型的准确性。然而，当它们两者都被修剪时，模型的精度可能会显著降低。这种交互作用被费雪信息矩阵的非对角元素捕获，在前一阶段被忽略。因此，我们可以通过使用对Fisher矩阵的块对角近似来更好地考虑剪枝问题中的相互作用，其中一个块对应于一个MHA层或一个FFN层，如下图所示。</p>
<p><img src="/../images/summery1016_imgs/157.png"></p>
<p>用贪婪算法近似地解决这个问题。在将掩模初始化即热启动）后，为每一轮选择一个具有最高Fisher信息的修剪头（或过滤器），并与当前掩模中的一个未修剪头（或过滤器）交换：</p>
<p><img src="/../images/summery1016_imgs/158.png"></p>
<p><strong>掩码微调：</strong></p>
<p>非零变量被调优到任何真实值，这样修剪后的模型就可以恢复其精度。通过线性最小二乘法进行分层重建。我们调整掩模变量以使最小化层重构误差，。从第一层到最后一层，我们用修剪模型中剩余的头&#x2F;滤波器重建原始模型的输出激活。正式形式如下：</p>
<p><img src="/../images/summery1016_imgs/159.png"></p>
<h2 id="实验-14"><a href="#实验-14" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/1510.png"></p>
<h1 id="16-随机森林预测剪枝架构"><a href="#16-随机森林预测剪枝架构" class="headerlink" title="16 随机森林预测剪枝架构"></a>16 随机森林预测剪枝架构</h1><h2 id="简介-15"><a href="#简介-15" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>PRUNING LARGE LANGUAGE MODELS VIA ACCURACY PREDICTOR</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023</td>
</tr>
<tr>
<td>代码</td>
<td></td>
</tr>
<tr>
<td>压缩技术</td>
<td>建立预测器预测剪枝体系结构</td>
</tr>
</tbody></table>
<h2 id="笔记-1"><a href="#笔记-1" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>目前，llm压缩的一些工作主要集中在模型量化上</li>
<li>注意层的重要性远高于MLP：</li>
</ol>
<p><img src="/../images/summery1016_imgs/163.png"></p>
<h2 id="方法-15"><a href="#方法-15" class="headerlink" title="方法"></a>方法</h2><p>构建架构-精度对：</p>
<p><img src="/../images/summery1016_imgs/161.png"></p>
<p>权重重要性评估：</p>
<p><img src="/../images/summery1016_imgs/162.png"></p>
<p>建立随机森林模型。</p>
<p>QLoRA微调恢复。</p>
<h2 id="实验-15"><a href="#实验-15" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/164.png"></p>
<h1 id="17-Wanda"><a href="#17-Wanda" class="headerlink" title="17 Wanda"></a>17 Wanda</h1><h2 id="简介-16"><a href="#简介-16" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>A SIMPLE AND EFFECTIVE PRUNING APPROACH FOR LARGE LANGUAGE MODELS</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/locuslab/wanda">locuslab&#x2F;wanda: A simple and effective LLM pruning approach. (github.com)</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>一次剪枝，不需要再训练或重量更新</td>
</tr>
</tbody></table>
<h2 id="笔记-2"><a href="#笔记-2" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>由于最近在llm中出现的大幅度特征的观察，我们的方法在每个输出的基础上，将最小幅度的权重乘以相应的输入激活。</li>
<li>到目前为止，许多显著的进展都集中在模型量化上，这是一个将参数被量化为更低的位级表示的过程</li>
<li>幅度修剪（Han et al.，2015），一种成熟的修剪方法，即使具有相对较低的稀疏性水平，在llm上也会显著失败</li>
<li>一旦llm达到一定规模（实际中约6B参数），一小组隐藏状态特征就会比其余特征大得多。这些离群值特征表现出几个有趣的特征。首先，它们有非常大的大小，大约是典型的隐藏状态值的100倍。其次，它们通常是稀疏的，并且存在于某些特定的特征维度中。最后，这些离群值特征对于llm的预测能力是至关重要的：在推理时消除这些特征将导致语言建模性能的显著下降</li>
<li>与SparseGPT不同，我们的方法不需要对修剪过的网络进行权值更新，这表明llm具有有效的精确的稀疏子网络，而不是它们仅仅存在于原始权值的邻域中</li>
<li>选择正确的比较组对于剪枝大型语言模型（LLMs）非常重要，即使在传统的Magnitude剪枝方法中也是如此</li>
</ol>
<h2 id="方法-16"><a href="#方法-16" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/171.png"></p>
<p><strong>我们在每个输出的基础上（图中的每一行）上比较和删除权重，其中权重重要性分数在每个输出神经元中进行局部比较</strong></p>
<p>对比SparseGPT：</p>
<p><img src="/../images/summery1016_imgs/172.png"></p>
<p>令$\lambda&#x3D;0$：</p>
<p><img src="/../images/summery1016_imgs/173.png"></p>
<h2 id="实验-16"><a href="#实验-16" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/174.png"></p>
<p>校准数据量：</p>
<p><img src="/../images/summery1016_imgs/175.png"></p>
<p>不同分组结果：</p>
<p><img src="/../images/summery1016_imgs/176.png"></p>
<h1 id="18-SparseBERT"><a href="#18-SparseBERT" class="headerlink" title="18 SparseBERT"></a>18 SparseBERT</h1><h2 id="简介-17"><a href="#简介-17" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Rethinking Network Pruning— under the Pre-train and Fine-tune Paradigm</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2021</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/dongkuanx27/SparseBERT">https://github.com/dongkuanx27/SparseBERT</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>SparseBERT将在微调阶段执行。它在修剪的同时保留了通用的和特定于任务的语言知识、幅度剪枝</td>
</tr>
</tbody></table>
<h2 id="笔记-3"><a href="#笔记-3" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>通过研究知识在训练前、微调和修剪过程中如何传递和丢失来填补这一空白，并提出一个知识感知的稀疏剪枝过程</li>
<li>最近的研究结果表明，自我注意和前馈层是过度参数化的，是最多计算消耗的部分</li>
</ol>
<h2 id="方法-17"><a href="#方法-17" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/181.png"></p>
<p><img src="/../images/summery1016_imgs/182.png"></p>
<p>SparseBERT使用没有微调的预先训练的BERT作为初始化模型，修剪自注意和前馈层的线性变换.</p>
<p>为了在剪枝过程中学习特定于任务的任务知识，同时保留通用知识，我们应用了知识蒸馏：采用特定任务的微调BERT作为教师网络，采用预先训练的BERT作为学生。我们将下游任务数据输入师生框架，以训练学生再现教师的行为。</p>
<p>蒸馏损失：</p>
<p><img src="/../images/summery1016_imgs/183.png"></p>
<p>蒸馏与剪枝并行：</p>
<p><img src="/../images/summery1016_imgs/184.png"></p>
<h2 id="实验-17"><a href="#实验-17" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/185.png"></p>
<h1 id="19-Compresso"><a href="#19-Compresso" class="headerlink" title="19 Compresso"></a>19 Compresso</h1><h2 id="简介-18"><a href="#简介-18" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th><strong>Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models.</strong></th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023</td>
</tr>
<tr>
<td>代码</td>
<td>(<a target="_blank" rel="noopener" href="https://github.com/microsoft/Moonlit/tree/main/Compresso">https://github.com/microsoft/Moonlit/tree/main/Compresso</a>)</td>
</tr>
<tr>
<td>压缩技术</td>
<td>使用指令调优数据集、提示词、端到端剪枝</td>
</tr>
</tbody></table>
<h2 id="笔记-4"><a href="#笔记-4" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>LLM培训由于其庞大的模型规模，资源非常密集。其次，llm的训练数据集是广泛的，而且由于法律限制，往往不可用。直接使用开源数据集可能会导致分布外的问题，因为剪枝数据的分布与预训练前的数据分布有很大的不同</li>
<li>大多数最先进的修剪方法都涉及到一个训练过程来更新梯度，并利用它们来估计权重的重要性，然而，由于两个主要原因，这些方法不能直接应用于llm。首先，它们是需要下游训练数据集。因此，修剪后的模型不能保留在不同任务之间的泛化能力。其次，llm的修剪过程需要大量的训练资源。</li>
<li>尽管它的速度很快，但一次性修剪也有其局限性。首先，它在很大程度上依赖于预先预定义的权重重要性度量来修剪决策，因此在所有层之间采用均匀稀疏比，而不考虑每个层的不同冗余。其次，与基于训练的剪枝相比，剩余模型参数的误差恢复很有限，这可能会影响最终的性能。我们的压缩机解决了所有这些限制。</li>
<li>使用指令对llm进行微调已被证明可以提高性能和对不可见任务的泛化</li>
</ol>
<h2 id="方法-18"><a href="#方法-18" class="headerlink" title="方法"></a>方法</h2><p>为了解决基于训练的剪枝中高训练成本和数据收集的挑战，我们将低秩适应（LoRA）纳入L0正则化，并使用指令调优数据集作为训练数据的替代方案。具体来说，我们利用可学习的二进制掩码来决定是否保留或修剪每个子模块（即，头、FFN中间维度和隐藏维度）。</p>
<p>然后，在指令调整过程中，采用L0正则化方法优化掩模值，同时通过LoRA更新模型参数。此外，与一次性LLM修剪方法相比，通常采用跨所有层的均匀稀疏比，压缩机自动学习改进的层级稀疏比。</p>
<p><img src="/../images/summery1016_imgs/191.png"></p>
<p>数据集：建议使用指令调优数据集作为修剪数据。尽管它们的分布不同于训练前的数据集，但它们已经证明了在微调预训练和收敛的llm以符合人类意图方面的成功</p>
<p>高效的基于训练的结构化修剪：</p>
<p>基本思想是： (i)我们引入一组二进制掩模Z∈{0,1}来指示是删除（Z &#x3D; 0）还是保留（Z &#x3D; 1）每个掩模子模块，从而表示剩余的模型大小；（ii）我们冻结原始LLM，利用LoRA向LLM的秩分解矩阵注入LLM可训练的每一层。这大大减少了可训练参数的数量和所需的GPU内存；（iii）我们使用增强的L0正则化联合优化这些掩模值和LoRA模块（方法。这确保了修剪后的模型大小满足给定的约束条件。</p>
<p>剪枝形式（采用Cofi）：</p>
<p><img src="/../images/summery1016_imgs/192.png"></p>
<p>引入Lora：</p>
<p><img src="/../images/summery1016_imgs/193.png"></p>
<p>定义稀疏性函数(无需手动选择剪枝比例)：</p>
<p><img src="/../images/summery1016_imgs/194.png"></p>
<p>$L_0$重参数化：</p>
<p><img src="/../images/summery1016_imgs/195.png"></p>
<p>惩罚项：</p>
<p><img src="/../images/summery1016_imgs/196.png"></p>
<p>训练目标是下一个令牌预测损失和$L_{0{reg}}$损失的组合。</p>
<p>剪枝过程中，我们将提示符放在输入文本之前。根据指令调优的实践（Taori et al.，2023），我们不计算提示部分的下一代令牌生成损失。协作提示在两个阶段的修剪和推理阶段都被使用:</p>
<p><img src="/../images/summery1016_imgs/197.png"></p>
<h2 id="实验-18"><a href="#实验-18" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/198.png" alt="image-20231106160054281"></p>
<h1 id="20-Cofi"><a href="#20-Cofi" class="headerlink" title="20 Cofi"></a>20 Cofi</h1><h2 id="简介-19"><a href="#简介-19" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Structured Pruning Learns Compact and Accurate Models</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>ACL</td>
</tr>
<tr>
<td>发表时间</td>
<td>2022</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/princeton-nlp/CoFiPruning">https://github.com/princeton-nlp/CoFiPruning</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>粗粒度和细粒度剪枝、分层精馏策略</td>
</tr>
</tbody></table>
<h2 id="笔记-5"><a href="#笔记-5" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>蒸馏方法需要大量的未标记数据，而且训练成本昂贵</li>
<li>经验证据表明，50%的层可以下降，而没有很大的精度下降，导致2×的加速。</li>
<li>FFN修剪的其他主要部分-前馈层（FFNs）-也被认为是过度参数化的</li>
<li>加速率是我们在整个论文中使用的一个主要度量方法，因为压缩率并不一定反映了推理延迟的实际改进</li>
<li>我们将这项工作的范围框架为针对特定任务的剪枝。我们希望未来的研究能够继续这一工作，因为与一般蒸馏相比，从大型预训练模型进行的修剪可能会导致更少的计算，并导致更灵活的模型结构</li>
</ol>
<h2 id="方法-19"><a href="#方法-19" class="headerlink" title="方法"></a>方法</h2><p><img src="/../images/summery1016_imgs/201.png"></p>
<p>目标稀疏：</p>
<p><img src="/../images/summery1016_imgs/202.png"></p>
<p>隐层蒸馏损失：</p>
<p><img src="/../images/summery1016_imgs/203.png"></p>
<p>动态映射关系：</p>
<p><img src="/../images/summery1016_imgs/204.png"></p>
<p>蒸馏损失：</p>
<p><img src="/../images/summery1016_imgs/205.png"></p>
<h2 id="实验-19"><a href="#实验-19" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/206.png"></p>
<h1 id="21-BIP"><a href="#21-BIP" class="headerlink" title="21 BIP"></a>21 BIP</h1><h2 id="简介-20"><a href="#简介-20" class="headerlink" title="简介"></a>简介</h2><table>
<thead>
<tr>
<th>名称</th>
<th>Advancing Model Pruning via Bi-level Optimization</th>
</tr>
</thead>
<tbody><tr>
<td>期刊</td>
<td>NeurIPS</td>
</tr>
<tr>
<td>发表时间</td>
<td>2022</td>
</tr>
<tr>
<td>代码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/OPTML-Group/BiP">https://github.com/OPTML-Group/BiP</a></td>
</tr>
<tr>
<td>压缩技术</td>
<td>剪枝-训练范式并行处理，双层优化</td>
</tr>
</tbody></table>
<h2 id="笔记-6"><a href="#笔记-6" class="headerlink" title="笔记"></a>笔记</h2><ol>
<li>正如彩票假说（LTH）所示，修剪也有提高其泛化能力的潜力</li>
<li>获得较高的剪枝模型精度（如IMP）和较高的计算效率（如一次性剪枝）</li>
<li>剪枝-再训练学习范式涵盖了两种任务：❶剪枝决定了模型权值的稀疏模式，以及❷训练保留非零权值来恢复模型的精度</li>
<li>底层和上层优化的数据批量选择：我们在实现（θ-step）和（m-step）时，采用不同的数据批量（具有相同的批量大小）。这是BLO公式的优点之一，它可以灵活地定制底层和上层问题</li>
<li>在m上的离散优化：我们遵循“凸松弛+硬阈值”机制。具体地说，我们将二进制掩蔽变量放宽为连续掩蔽分数m∈[0,1]。然后我们得到基于松弛m的后传递损失梯度</li>
</ol>
<h2 id="方法-20"><a href="#方法-20" class="headerlink" title="方法"></a>方法</h2><p>将剪枝任务（即❶）和模型再训练任务（即❷）解释为两个优化级别，其中前者被表述为上层优化问题，并依赖于低层次再训练任务的优化。因此，我们将模型剪枝问题转换为以下BLO问题（❷嵌套在❶中）：</p>
<p><img src="/../images/summery1016_imgs/207.png"></p>
<p>BLO可以灵活地在上层和下层的优化级别上分别使用不匹配的修剪和再训练目标。这种灵活性允许我们在(1)中规范底层训练目标函数，并在两个级别上定制已实现的优化方法。更具体地说，我们可以使用一个数据批处理（称为B2）来更新上层修剪掩码m，而不是不同于用于获取底层解决方案θ∗(m)的数据批处理（称为B1）。由此产生的BLO过程可以模拟元学习的想法来改进模型泛化[98]，其中低级问题使用B1对θ进行微调，而上层问题使用B2验证稀疏感知精细模型（m⊙θ∗(m)）的泛化。</p>
<p>在梯度下降的情况下，公式中的目标函数的梯度产生：</p>
<p><img src="/../images/summery1016_imgs/212.png"></p>
<p>IG：</p>
<p><img src="/../images/summery1016_imgs/213.png" alt="image-20231106190027013"></p>
<p>由于矩阵反演和二阶偏导数的存在，精确的IG公式(3)仍然难以计算。为了简化它，我们施加了无黑森假设，∇2θℓ&#x3D;0，它一般是温和的</p>
<p>近似：</p>
<p><img src="/../images/summery1016_imgs/214.png"></p>
<p>使用一阶近似：</p>
<p><img src="/../images/summery1016_imgs/215.png"></p>
<p>两个步骤：</p>
<ul>
<li><p>用于模型再训练的较低级别的SGD：</p>
<p><img src="/../images/summery1016_imgs/216.png" alt="image-20231106190355644"></p>
</li>
<li><p>用于修剪的上层SPGD：</p>
<p><img src="/../images/summery1016_imgs/217.png"></p>
</li>
</ul>
<p><img src="/../images/summery1016_imgs/218.png"></p>
<h2 id="实验-20"><a href="#实验-20" class="headerlink" title="实验"></a>实验</h2><p><img src="/../images/summery1016_imgs/219.png"></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ghtll</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://ghtll.github.io/2023/10/16/summery1016/">https://ghtll.github.io/2023/10/16/summery1016/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ghtll</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/">
                                    <span class="chip bg-color">模型压缩</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/10/27/CoFi/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="CoFi">
                        
                        <span class="card-title">CoFi</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-10-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ghtll
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/10/09/PruneOnceforAll/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/21.jpg" class="responsive-img" alt="PruneOnceforAll">
                        
                        <span class="card-title">PruneOnceforAll</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            给预训练模型剪枝,之后针对特定任务进行微调
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-10-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" class="post-category">
                                    文献阅读
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%89%AA%E6%9E%9D/">
                        <span class="chip bg-color">剪枝</span>
                    </a>
                    
                    <a href="/tags/%E8%92%B8%E9%A6%8F/">
                        <span class="chip bg-color">蒸馏</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: ヾ(≧∪≦*)ノ〃<br />'
            + '文章作者: gaohaotian<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->


<!-- 代码块收缩 -->



    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <a href="/about" target="_blank">gaohaotian</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2023";
                        var startMonth = "9";
                        var startDate = "17";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ghtll" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:260878610@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=260878610" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 260878610" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/sakura.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>

</html>
